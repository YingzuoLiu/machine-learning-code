{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid 激活函数\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# 计算交叉熵损失\n",
    "def lossfunction(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    loss = - (1/m) * np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "# 逻辑回归模型训练\n",
    "def logistic_regression(X, y, learning_rate=0.01, epochs=1000):\n",
    "    m, n = X.shape  # m 是样本数量，n 是特征数量\n",
    "    w = np.zeros((n, 1))  # 初始化权重\n",
    "    b = 0  # 初始化偏置\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        # 前向传播\n",
    "        z = np.dot(X, w) + b\n",
    "        y_pred = sigmoid(z)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = lossfunction(y, y_pred)\n",
    "        \n",
    "        # 反向传播（计算梯度）\n",
    "        dz = y_pred - y  # 误差（梯度）\n",
    "        dw = (1/m) * np.dot(X.T, dz)  # 计算 w 的梯度\n",
    "        db = (1/m) * np.sum(dz)  # 计算 b 的梯度\n",
    "\n",
    "        # 更新参数\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "\n",
    "    return w, b"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
