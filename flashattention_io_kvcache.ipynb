{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5b6f3e",
   "metadata": {},
   "source": [
    "# ‚ö° FlashAttention vs Standard Attention (with KV Cache & Inference Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e63286fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d253e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 4\n",
    "dim = 8\n",
    "\n",
    "torch.manual_seed(42)\n",
    "Q = torch.randn(seq_len, dim)\n",
    "K = torch.randn(seq_len, dim)\n",
    "V = torch.randn(seq_len, dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc659b01",
   "metadata": {},
   "source": [
    "## üß† Standard Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9bfcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2667,  0.2371, -0.0554,  0.1298,  0.3541, -0.1906, -0.6448, -0.0085],\n",
       "        [ 0.1086,  0.2444, -0.2164,  0.3814,  0.0631, -0.5633, -1.1007, -0.3306],\n",
       "        [ 0.4947, -0.1095, -0.5350,  0.3420, -0.6224, -0.4772,  0.3223,  0.2335],\n",
       "        [ 0.5705, -0.0146, -0.2775,  0.3238, -0.4680, -0.4084,  0.1981,  0.3296]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_attention(Q, K, V):\n",
    "    attn_scores = Q @ K.T\n",
    "    attn_weights = F.softmax(attn_scores / np.sqrt(Q.size(1)), dim=-1)\n",
    "    output = attn_weights @ V\n",
    "    return output, attn_weights\n",
    "\n",
    "standard_out, attn_weights = standard_attention(Q, K, V)\n",
    "standard_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c23b6",
   "metadata": {},
   "source": [
    "## ‚ö° FlashAttention (Row-wise fused computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57233e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2667,  0.2371, -0.0554,  0.1298,  0.3541, -0.1906, -0.6448, -0.0085],\n",
       "        [ 0.1086,  0.2444, -0.2164,  0.3814,  0.0631, -0.5633, -1.1007, -0.3306],\n",
       "        [ 0.4947, -0.1095, -0.5350,  0.3420, -0.6224, -0.4772,  0.3223,  0.2335],\n",
       "        [ 0.5705, -0.0146, -0.2775,  0.3238, -0.4680, -0.4084,  0.1981,  0.3296]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flash_attention(Q, K, V):\n",
    "    L, d = Q.size()\n",
    "    output = torch.zeros_like(Q)\n",
    "    for i in range(L):\n",
    "        q_i = Q[i]\n",
    "        scores = (q_i @ K.T) / np.sqrt(d)\n",
    "        scores = scores - scores.max()\n",
    "        weights = torch.exp(scores)\n",
    "        weights_sum = weights.sum()\n",
    "        softmax_weights = weights / weights_sum\n",
    "        output[i] = softmax_weights @ V\n",
    "    return output\n",
    "\n",
    "flash_out = flash_attention(Q, K, V)\n",
    "flash_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ef341",
   "metadata": {},
   "source": [
    "## ‚úÖ Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50bf7487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max difference: 3.5762786865234375e-07\n"
     ]
    }
   ],
   "source": [
    "diff = torch.abs(standard_out - flash_out).max()\n",
    "print(\"Max difference:\", diff.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f3e47",
   "metadata": {},
   "source": [
    "## üß† KV ÁºìÂ≠òÊú∫Âà∂Ê®°Êãü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe604cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4389,  0.3399,  0.3086,  0.1112,  0.4843, -0.0900, -0.6649,  0.2127]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_K = K[:3]\n",
    "cached_V = V[:3]\n",
    "new_q = Q[3].unsqueeze(0)\n",
    "\n",
    "def flash_attention_with_kv_cache(q, cached_K, cached_V):\n",
    "    scores = (q @ cached_K.T) / np.sqrt(q.size(-1))\n",
    "    scores = scores - scores.max()\n",
    "    weights = torch.softmax(scores, dim=-1)\n",
    "    output = weights @ cached_V\n",
    "    return output\n",
    "\n",
    "kv_output = flash_attention_with_kv_cache(new_q, cached_K, cached_V)\n",
    "kv_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5298d9d",
   "metadata": {},
   "source": [
    "## üîÅ Decoder Êé®ÁêÜÂæ™ÁéØÁ§∫‰æãÔºàKV ÁºìÂ≠ò + FlashAttention È£éÊ†ºÔºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87163dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4570, -0.1023, -0.5992,  0.4771,  0.7262,  0.0912, -0.3891,  0.5279],\n",
       "        [-0.3008,  0.1724, -0.0134,  0.7069,  1.0214,  0.2903,  0.4987,  0.4347],\n",
       "        [ 1.0657,  0.7124, -1.0994, -0.6095,  0.1675,  1.1947,  0.4632,  0.5482],\n",
       "        [ 0.0714,  0.0161, -1.0562,  0.3643,  0.3505, -0.1191,  0.0595,  0.5450],\n",
       "        [ 0.1705,  0.0327, -0.6371,  0.5708,  0.3913,  0.0094,  0.5202,  0.4017]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 5\n",
    "dim = 8\n",
    "torch.manual_seed(42)\n",
    "\n",
    "Q_seq = torch.randn(seq_len, dim)\n",
    "K_seq = torch.randn(seq_len, dim)\n",
    "V_seq = torch.randn(seq_len, dim)\n",
    "\n",
    "K_all, V_all = [], []\n",
    "outputs = []\n",
    "\n",
    "def flash_attention_step(q, K_cache, V_cache):\n",
    "    K_tensor = torch.stack(K_cache)\n",
    "    V_tensor = torch.stack(V_cache)\n",
    "    scores = (q @ K_tensor.T) / np.sqrt(q.size(-1))\n",
    "    scores = scores - scores.max()\n",
    "    weights = torch.softmax(scores, dim=-1)\n",
    "    output = weights @ V_tensor\n",
    "    return output.squeeze(0)\n",
    "\n",
    "for t in range(seq_len):\n",
    "    q_t = Q_seq[t].unsqueeze(0)\n",
    "    k_t = K_seq[t]\n",
    "    v_t = V_seq[t]\n",
    "    K_all.append(k_t)\n",
    "    V_all.append(v_t)\n",
    "    out_t = flash_attention_step(q_t, K_all, V_all)\n",
    "    outputs.append(out_t)\n",
    "\n",
    "decoder_outputs = torch.stack(outputs)\n",
    "decoder_outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
