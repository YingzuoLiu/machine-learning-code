{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ec3de2",
   "metadata": {},
   "source": [
    "# ğŸ¯ å®éªŒèƒŒæ™¯ä¸åº”ç”¨åœºæ™¯ï¼šå»åæ’åºæ¨¡å‹åœ¨æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨\n",
    "\n",
    "åœ¨å¤§å¤šæ•°å®é™…æ¨èç³»ç»Ÿä¸­ï¼Œ**ç”¨æˆ·ç‚¹å‡»è¡Œä¸ºå¸¸ç”¨äºè®­ç»ƒæ’åºæ¨¡å‹**ï¼Œç„¶è€Œè¿™äº›ç‚¹å‡»æ•°æ®å¾€å¾€å­˜åœ¨ä¸¤ç±»ä¸¥é‡åå·®ï¼š\n",
    "\n",
    "1. **æ ‡ç­¾åå·®ï¼ˆLabel Biasï¼‰**ï¼šç”¨æˆ·ç‚¹å‡»æœªå¿…è¡¨ç¤ºçœŸå®å…´è¶£ï¼Œæœªç‚¹å‡»ä¹Ÿä¸ä»£è¡¨ä¸æ„Ÿå…´è¶£ã€‚ä¾‹å¦‚ï¼Œä¸€äº›å•†å“ç”±äºå›¾æ–‡å¸å¼•åŠ›è¢«è¯¯ç‚¹ï¼Œè€Œå¦ä¸€äº›æœ‰ä»·å€¼å•†å“æœªè¢«æ³¨æ„åˆ°ã€‚\n",
    "\n",
    "2. **æ›å…‰åå·®ï¼ˆExposure Biasï¼‰**ï¼šç”¨æˆ·åªèƒ½çœ‹åˆ°æ¨èç³»ç»Ÿä¸»åŠ¨æ›å…‰çš„å†…å®¹ï¼Œå¯¼è‡´è®­ç»ƒæ ·æœ¬åˆ†å¸ƒä¸çœŸå®å…´è¶£åˆ†å¸ƒä¸ä¸€è‡´ã€‚ç³»ç»Ÿæ›´å€¾å‘äºæ›å…‰çƒ­é—¨å•†å“ï¼Œå†·é—¨å†…å®¹å¾ˆéš¾è·å¾—ç‚¹å‡»ã€‚\n",
    "\n",
    "è¿™äº›åå·®ç›´æ¥å½±å“æ’åºæ¨¡å‹çš„è®­ç»ƒè´¨é‡ï¼Œå®¹æ˜“å¯¼è‡´æ¨èç»“æœè¿‡åº¦é›†ä¸­åœ¨çƒ­é—¨å†…å®¹ã€éš¾ä»¥æ•æ‰ç”¨æˆ·çš„çœŸå®ä¸ªæ€§åŒ–éœ€æ±‚ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02758bd",
   "metadata": {},
   "source": [
    "# LambdaMART vs Debiased LambdaMART + IPW\n",
    "\n",
    "é€šè¿‡æ¨¡æ‹Ÿæ’åºæ¨èæ•°æ®ï¼Œæ¯”è¾ƒï¼š\n",
    "- Click Label + LambdaMARTï¼ˆBaselineï¼‰\n",
    "- Denoised Label + LambdaMARTï¼ˆDebiasedï¼‰\n",
    "- Denoised Label + IPWæƒé‡ + LambdaMARTï¼ˆDebiasedï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ce714",
   "metadata": {},
   "source": [
    "## æ„é€ æ¨¡æ‹Ÿæ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e847e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>click</th>\n",
       "      <th>dwell_time</th>\n",
       "      <th>is_interest</th>\n",
       "      <th>is_conformity</th>\n",
       "      <th>click_label</th>\n",
       "      <th>denoised_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.596625</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>24.102547</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>8.331949</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>39.106061</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>75.536141</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  click  dwell_time  is_interest  is_conformity  \\\n",
       "0        0       13      1    1.596625         True          False   \n",
       "1        0       39      1   24.102547         True          False   \n",
       "2        0       30      0    8.331949        False          False   \n",
       "3        0       45      1   39.106061         True          False   \n",
       "4        0       17      1   75.536141         True          False   \n",
       "\n",
       "   click_label  denoised_label  \n",
       "0            1               1  \n",
       "1            1               1  \n",
       "2            0               0  \n",
       "3            1               1  \n",
       "4            1               1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_users = 100\n",
    "n_items = 50\n",
    "\n",
    "data = []\n",
    "for user in range(n_users):\n",
    "    items = np.random.choice(n_items, size=10, replace=False)\n",
    "    for item in items:\n",
    "        # æ¨¡æ‹Ÿç‚¹å‡»ï¼š70%ç”±å…´è¶£å†³å®šï¼Œ30%ä¸ºä»ä¼—ç‚¹å‡»\n",
    "        is_interest = np.random.rand() < 0.6\n",
    "        is_conformity = not is_interest and (np.random.rand() < 0.5)\n",
    "        click = int(is_interest or is_conformity)\n",
    "        dwell_time = np.random.rand() * 100 if click else np.random.rand() * 10\n",
    "        data.append([user, item, click, dwell_time, is_interest, is_conformity])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"user_id\", \"item_id\", \"click\", \"dwell_time\", \"is_interest\", \"is_conformity\"])\n",
    "df[\"click_label\"] = df[\"click\"]\n",
    "df[\"denoised_label\"] = df[\"is_interest\"].astype(int)  # å»æ‰ conformity çš„å½±å“\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d2e0f",
   "metadata": {},
   "source": [
    "## ç‰¹å¾ç¼–ç  + æ„é€  group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d59cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_enc = LabelEncoder()\n",
    "item_enc = LabelEncoder()\n",
    "df[\"user_id\"] = user_enc.fit_transform(df[\"user_id\"])\n",
    "df[\"item_id\"] = item_enc.fit_transform(df[\"item_id\"])\n",
    "\n",
    "# æ„é€  Groupï¼ˆæ¯ä¸ªç”¨æˆ·æ˜¯ä¸€ç»„ï¼‰\n",
    "df = df.sort_values(\"user_id\")\n",
    "group_sizes = df.groupby(\"user_id\").size().tolist()\n",
    "\n",
    "# è®­ç»ƒæµ‹è¯•åˆ’åˆ†\n",
    "train_df = df.sample(frac=0.8, random_state=1)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "group_train = train_df.groupby(\"user_id\").size().tolist()\n",
    "group_test = test_df.groupby(\"user_id\").size().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a6e9d3",
   "metadata": {},
   "source": [
    "## å®šä¹‰æ’åºè¯„ä¼°æŒ‡æ ‡ï¼ˆAUC, NDCG, MAPï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240cbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asarray(r, dtype=np.float32)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    return dcg_at_k(r, k) / dcg_max if dcg_max else 0.\n",
    "\n",
    "def evaluate(model, test_df, label_col):\n",
    "    X_test = test_df[[\"user_id\", \"item_id\"]]\n",
    "    y_true = test_df[label_col].values\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    test_df = test_df.copy()\n",
    "    test_df[\"score\"] = y_pred\n",
    "    test_df[\"label\"] = y_true\n",
    "    ndcgs = []\n",
    "    for _, group in test_df.groupby(\"user_id\"):\n",
    "        ranked = group.sort_values(\"score\", ascending=False)\n",
    "        ndcg = ndcg_at_k(ranked[\"label\"].values, 5)\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return auc, np.mean(ndcgs), ap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90b6e3",
   "metadata": {},
   "source": [
    "## Baseline: Click Label + LambdaMART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eec219d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 2\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's ndcg@5: 0.951479\n"
     ]
    }
   ],
   "source": [
    "train_set = lgb.Dataset(train_df[[\"user_id\", \"item_id\"]], label=train_df[\"click_label\"], group=group_train)\n",
    "test_set = lgb.Dataset(test_df[[\"user_id\", \"item_id\"]], label=test_df[\"click_label\"], group=group_test, reference=train_set, free_raw_data=False)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"ndcg_eval_at\": [5],\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"boosting_type\": \"gbdt\"\n",
    "}\n",
    "\n",
    "model_baseline = lgb.train(params, train_set, num_boost_round=100, valid_sets=[test_set],\n",
    "                           callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "auc1, ndcg1, map1 = evaluate(model_baseline, test_df, \"click_label\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1ef9d",
   "metadata": {},
   "source": [
    "## Debiased: Denoised Label + LambdaMART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56cf1a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 2\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@5: 0.926893\n"
     ]
    }
   ],
   "source": [
    "train_set_denoised = lgb.Dataset(train_df[[\"user_id\", \"item_id\"]], label=train_df[\"denoised_label\"], group=group_train)\n",
    "test_set_denoised = lgb.Dataset(test_df[[\"user_id\", \"item_id\"]],\n",
    "                                label=test_df[\"denoised_label\"],\n",
    "                                group=group_test,\n",
    "                                reference=train_set_denoised,\n",
    "                                free_raw_data=False)\n",
    "\n",
    "model_denoised = lgb.train(params, train_set_denoised, num_boost_round=100, valid_sets=[test_set_denoised],\n",
    "                           callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "auc2, ndcg2, map2 = evaluate(model_denoised, test_df, \"denoised_label\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055d13c",
   "metadata": {},
   "source": [
    "## Debiased + IPW æƒé‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd1f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Calculating query weights...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 150\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 2\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's ndcg@5: 0.923977\n"
     ]
    }
   ],
   "source": [
    "# æ¨¡æ‹Ÿæ›å…‰ä½ç½®åå·®ï¼Œæ„é€ IPWæƒé‡ï¼ˆè¶Šé åè¶Šéš¾è¢«çœ‹è§ï¼‰\n",
    "def simulate_exposure_bias(row):\n",
    "    position = np.random.randint(1, 11)\n",
    "    prob = 1.0 / position\n",
    "    return prob\n",
    "\n",
    "train_df[\"exposure_prob\"] = train_df.apply(simulate_exposure_bias, axis=1)\n",
    "train_df[\"ipw_weight\"] = 1.0 / (train_df[\"exposure_prob\"] + 1e-6)\n",
    "\n",
    "train_set_ipw = lgb.Dataset(train_df[[\"user_id\", \"item_id\"]],\n",
    "                            label=train_df[\"denoised_label\"],\n",
    "                            group=group_train,\n",
    "                            weight=train_df[\"ipw_weight\"])\n",
    "\n",
    "test_set_ipw = lgb.Dataset(test_df[[\"user_id\", \"item_id\"]],\n",
    "                           label=test_df[\"denoised_label\"],\n",
    "                           group=group_test,\n",
    "                           reference=train_set_ipw,\n",
    "                           free_raw_data=False)\n",
    "\n",
    "model_ipw = lgb.train(params, train_set_ipw, num_boost_round=100, valid_sets=[test_set_ipw],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "auc3, ndcg3, map3 = evaluate(model_ipw, test_df, \"denoised_label\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255ace9",
   "metadata": {},
   "source": [
    "## æ¨¡å‹æ•ˆæœå¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2c7075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Click Label):       AUC = 0.5113, NDCG@5 = 0.9044, MAP = 0.8154\n",
      "Debiased (Denoised Label):    AUC = 0.5483, NDCG@5 = 0.7249, MAP = 0.6705\n",
      "Debiased + IPW (Our Method):  AUC = 0.5413, NDCG@5 = 0.7240, MAP = 0.6280\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline (Click Label):       AUC = %.4f, NDCG@5 = %.4f, MAP = %.4f\" % (auc1, ndcg1, map1))\n",
    "print(\"Debiased (Denoised Label):    AUC = %.4f, NDCG@5 = %.4f, MAP = %.4f\" % (auc2, ndcg2, map2))\n",
    "print(\"Debiased + IPW (Our Method):  AUC = %.4f, NDCG@5 = %.4f, MAP = %.4f\" % (auc3, ndcg3, map3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
