{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ec3de2",
   "metadata": {},
   "source": [
    "# 🎯 实验背景与应用场景：去偏排序模型在推荐系统中的应用\n",
    "\n",
    "在大多数实际推荐系统中，**用户点击行为常用于训练排序模型**，然而这些点击数据往往存在两类严重偏差：\n",
    "\n",
    "1. **标签偏差（Label Bias）**：用户点击未必表示真实兴趣，未点击也不代表不感兴趣。例如，一些商品由于图文吸引力被误点，而另一些有价值商品未被注意到。\n",
    "\n",
    "2. **曝光偏差（Exposure Bias）**：用户只能看到推荐系统主动曝光的内容，导致训练样本分布与真实兴趣分布不一致。系统更倾向于曝光热门商品，冷门内容很难获得点击。\n",
    "\n",
    "这些偏差直接影响排序模型的训练质量，容易导致推荐结果过度集中在热门内容、难以捕捉用户的真实个性化需求。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02758bd",
   "metadata": {},
   "source": [
    "# LambdaMART vs Debiased LambdaMART + IPW\n",
    "\n",
    "通过模拟排序推荐数据，比较：\n",
    "- Click Label + LambdaMART（Baseline）\n",
    "- Denoised Label + LambdaMART（Debiased）\n",
    "- Denoised Label + IPW权重 + LambdaMART（Debiased）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ce714",
   "metadata": {},
   "source": [
    "## 构造模拟数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e847e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>click</th>\n",
       "      <th>dwell_time</th>\n",
       "      <th>is_interest</th>\n",
       "      <th>is_conformity</th>\n",
       "      <th>click_label</th>\n",
       "      <th>denoised_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.596625</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>24.102547</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>8.331949</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>39.106061</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>75.536141</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  click  dwell_time  is_interest  is_conformity  \\\n",
       "0        0       13      1    1.596625         True          False   \n",
       "1        0       39      1   24.102547         True          False   \n",
       "2        0       30      0    8.331949        False          False   \n",
       "3        0       45      1   39.106061         True          False   \n",
       "4        0       17      1   75.536141         True          False   \n",
       "\n",
       "   click_label  denoised_label  \n",
       "0            1               1  \n",
       "1            1               1  \n",
       "2            0               0  \n",
       "3            1               1  \n",
       "4            1               1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_users = 100\n",
    "n_items = 50\n",
    "\n",
    "data = []\n",
    "for user in range(n_users):\n",
    "    items = np.random.choice(n_items, size=10, replace=False)\n",
    "    for item in items:\n",
    "        # 模拟点击：70%由兴趣决定，30%为从众点击\n",
    "        is_interest = np.random.rand() < 0.6\n",
    "        is_conformity = not is_interest and (np.random.rand() < 0.5)\n",
    "        click = int(is_interest or is_conformity)\n",
    "        dwell_time = np.random.rand() * 100 if click else np.random.rand() * 10\n",
    "        data.append([user, item, click, dwell_time, is_interest, is_conformity])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"user_id\", \"item_id\", \"click\", \"dwell_time\", \"is_interest\", \"is_conformity\"])\n",
    "df[\"click_label\"] = df[\"click\"]\n",
    "df[\"denoised_label\"] = df[\"is_interest\"].astype(int)  # 去掉 conformity 的影响\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d2e0f",
   "metadata": {},
   "source": [
    "## 特征编码 + 构造 group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d59cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_enc = LabelEncoder()\n",
    "item_enc = LabelEncoder()\n",
    "df[\"user_id\"] = user_enc.fit_transform(df[\"user_id\"])\n",
    "df[\"item_id\"] = item_enc.fit_transform(df[\"item_id\"])\n",
    "\n",
    "# 构造 Group（每个用户是一组）\n",
    "df = df.sort_values(\"user_id\")\n",
    "group_sizes = df.groupby(\"user_id\").size().tolist()\n",
    "\n",
    "# 训练测试划分\n",
    "train_df = df.sample(frac=0.8, random_state=1)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "group_train = train_df.groupby(\"user_id\").size().tolist()\n",
    "group_test = test_df.groupby(\"user_id\").size().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a6e9d3",
   "metadata": {},
   "source": [
    "## 定义排序评估指标（AUC, NDCG, MAP）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240cbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asarray(r, dtype=np.float32)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    return dcg_at_k(r, k) / dcg_max if dcg_max else 0.\n",
    "\n",
    "def evaluate(model, test_df, label_col):\n",
    "    X_test = test_df[[\"user_id\", \"item_id\"]]\n",
    "    y_true = test_df[label_col].values\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    test_df = test_df.copy()\n",
    "    test_df[\"score\"] = y_pred\n",
    "    test_df[\"label\"] = y_true\n",
    "    ndcgs = []\n",
    "    for _, group in test_df.groupby(\"user_id\"):\n",
    "        ranked = group.sort_values(\"score\", ascending=False)\n",
    "        ndcg = ndcg_at_k(ranked[\"label\"].values, 5)\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return auc, np.mean(ndcgs), ap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90b6e3",
   "metadata": {},
   "source": [
    "## Baseline: Click Label + LambdaMART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eec219d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 2\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's ndcg@5: 0.951479\n"
     ]
    }
   ],
   "source": [
    "train_set = lgb.Dataset(train_df[[\"user_id\", \"item_id\"]], label=train_df[\"click_label\"], group=group_train)\n",
    "test_set = lgb.Dataset(test_df[[\"user_id\", \"item_id\"]], label=test_df[\"click_label\"], group=group_test, reference=train_set, free_raw_data=False)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"ndcg_eval_at\": [5],\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"boosting_type\": \"gbdt\"\n",
    "}\n",
    "\n",
    "model_baseline = lgb.train(params, train_set, num_boost_round=100, valid_sets=[test_set],\n",
    "                           callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "auc1, ndcg1, map1 = evaluate(model_baseline, test_df, \"click_label\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1ef9d",
   "metadata": {},
   "source": [
    "## Debiased: Denoised Label + LambdaMART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56cf1a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 2\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@5: 0.926893\n"
     ]
    }
   ],
   "source": [
    "train_set_denoised = lgb.Dataset(train_df[[\"user_id\", \"item_id\"]], label=train_df[\"denoised_label\"], group=group_train)\n",
    "test_set_denoised = lgb.Dataset(test_df[[\"user_id\", \"item_id\"]],\n",
    "                                label=test_df[\"denoised_label\"],\n",
    "                                group=group_test,\n",
    "                                reference=train_set_denoised,\n",
    "                                free_raw_data=False)\n",
    "\n",
    "model_denoised = lgb.train(params, train_set_denoised, num_boost_round=100, valid_sets=[test_set_denoised],\n",
    "                           callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "auc2, ndcg2, map2 = evaluate(model_denoised, test_df, \"denoised_label\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055d13c",
   "metadata": {},
   "source": [
    "## Debiased + IPW 权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd1f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Calculating query weights...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 150\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 2\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's ndcg@5: 0.923977\n"
     ]
    }
   ],
   "source": [
    "# 模拟曝光位置偏差，构造IPW权重（越靠后越难被看见）\n",
    "def simulate_exposure_bias(row):\n",
    "    position = np.random.randint(1, 11)\n",
    "    prob = 1.0 / position\n",
    "    return prob\n",
    "\n",
    "train_df[\"exposure_prob\"] = train_df.apply(simulate_exposure_bias, axis=1)\n",
    "train_df[\"ipw_weight\"] = 1.0 / (train_df[\"exposure_prob\"] + 1e-6)\n",
    "\n",
    "train_set_ipw = lgb.Dataset(train_df[[\"user_id\", \"item_id\"]],\n",
    "                            label=train_df[\"denoised_label\"],\n",
    "                            group=group_train,\n",
    "                            weight=train_df[\"ipw_weight\"])\n",
    "\n",
    "test_set_ipw = lgb.Dataset(test_df[[\"user_id\", \"item_id\"]],\n",
    "                           label=test_df[\"denoised_label\"],\n",
    "                           group=group_test,\n",
    "                           reference=train_set_ipw,\n",
    "                           free_raw_data=False)\n",
    "\n",
    "model_ipw = lgb.train(params, train_set_ipw, num_boost_round=100, valid_sets=[test_set_ipw],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "auc3, ndcg3, map3 = evaluate(model_ipw, test_df, \"denoised_label\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255ace9",
   "metadata": {},
   "source": [
    "## 模型效果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2c7075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Click Label):       AUC = 0.5113, NDCG@5 = 0.9044, MAP = 0.8154\n",
      "Debiased (Denoised Label):    AUC = 0.5483, NDCG@5 = 0.7249, MAP = 0.6705\n",
      "Debiased + IPW (Our Method):  AUC = 0.5413, NDCG@5 = 0.7240, MAP = 0.6280\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline (Click Label):       AUC = %.4f, NDCG@5 = %.4f, MAP = %.4f\" % (auc1, ndcg1, map1))\n",
    "print(\"Debiased (Denoised Label):    AUC = %.4f, NDCG@5 = %.4f, MAP = %.4f\" % (auc2, ndcg2, map2))\n",
    "print(\"Debiased + IPW (Our Method):  AUC = %.4f, NDCG@5 = %.4f, MAP = %.4f\" % (auc3, ndcg3, map3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
